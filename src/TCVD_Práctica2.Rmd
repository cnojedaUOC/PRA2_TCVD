---
title: 'Tipología y ciclo de vida de los datos: Práctica 2 - Limpieza y análisis de datos'
author: "Autoras: Eva Garía Ocaña y Carmen nieves Ojeda Guerra"
date: "Enero 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Descripción del dataset
******

El _dataset_ escogido para el trabajo es el **Breast Cancer Wisconsin (Diagnostic) Data Set** de UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) que analiza la incidencia del cáncer de mama en una población de 569 mujeres.

**Motivación:** Según la OMS, el cáncer de mama es el tipo de cáncer más común, con más de 2,2 millones de casos en 2020 y cerca de una de cada 12 mujeres enfermarán de cáncer de mama a lo largo de su vida. El cáncer de mama es la principal causa de mortalidad en las mujeres. En 2020, alrededor de 685000 mujeres fallecieron como consecuencia de esa enfermedad. Sin embargo, desde 1980 se han realizado importantes avances en el tratamiento del cáncer de mama debido a la combinación de la **detección precoz** y las terapias eficaces, basadas en cirugía, radioterapia y farmacoterapia (https://www.who.int/es/news-room/fact-sheets/detail/breast-cancer, marzo 2021). En España, según los últimos datos recogidos por el Sistema Europeo de Información del Cáncer (ECIS) de 2020, aproximadamente el 30% de los cánceres diagnosticados en mujeres se originan en la mama (https://www.geicam.org/sala-de-prensa/el-cancer-de-mama-en-espana, 2021). Una detección
temprana de la presencia de células cancerosas malignas aumenta la posibilidad de vida de las pacientes, sobre todo cuando se localiza un tumor pequeño y aún no ramificado. Para la realización de este estudio, el análisis de los datos obtenidos a partir de la información de estas células puede detectar la malignidad o benignidad de las mismas.

El objetivo de este trabajo es analizar el conjunto de datos indicado anteriormente para ver qué atributos o características influyen mayormente en que un tumor sea considera benigno o maligno y, posteriormente, realizar un clasificador que ayude a indicar si una muestra de tumor es benigna o no. 

**Potencial analítico del conjunto de datos:** Debido a las características del conjunto de datos (atributos de los que dispone) se pueden plantear preguntas que ayuden a comprender mejor cómo afectan los factores clave en la población estudiada y analizar qué variables pueden ser decisivas a la hora de conocer si un tumor es benigno o maligno. Una medida del potencial del conjunto de datos se puede ver en la cantidad de artículos de reconocido prestigio que lo usan en sus investigaciones, como por ejemplo:

1- Chien-Hsing Chen, _A hybrid intelligent model of analyzing clinical breast cancer data using clustering techniques with feature selection_, Applied Soft Computing, Volume 20, 2014, Pages 4-14, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2013.10.024.

2- Lingxi Peng, Wenbin Chen, Wubai Zhou, Fufang Li, Jin Yang, Jiandong Zhang, _An immune-inspired semi-supervised algorithm for breast cancer diagnosis_,
Computer Methods and Programs in Biomedicine, Volume 134, 2016, Pages 259-265, ISSN 0169-2607, https://doi.org/10.1016/j.cmpb.2016.07.020.

3- Bichen Zheng, Sang Won Yoon, Sarah S. Lam, _Breast cancer diagnosis based on feature extraction using a hybrid of K-means and support vector machine algorithms_, Expert Systems with Applications, Volume 41, Issue 4, Part 1, 2014,
Pages 1476-1482, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2013.08.044.

4- S. Punitha, Thompson Stephan, Amir H. Gandomi, _A Novel Breast Cancer Diagnosis Scheme With Intelligent Feature and Parameter Selections_,
Computer Methods and Programs in Biomedicine, 2021, 106432, ISSN 0169-2607, https://doi.org/10.1016/j.cmpb.2021.106432.

Para comenzar el análisis, se carga el _dataset_ desde la fuente origen:

```{r message= FALSE, warning=FALSE}
breast_data <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", sep = ",", col.names = c("ID", "Diagnosis", "Radius_mean", "Texture_mean", "Perimeter_mean", "Area_mean", "Smoothness_mean", "Compactness_mean", "Concavity_mean", "Concave.points_mean", "Symmetry_mean", "Fractal_dimension_mean", "Radius_se", "Texture_se", "Perimeter_se", "Area_se", "Smoothness_se", "Compactness_se", "Concavity_se", "Concave.points_se", "Symmetry_se", "Fractal_dimension_se", "Radius_worst", "Texture_worst","Perimeter_worst", "Area_worst", "Smoothness_worst", "Compactness_worst", "Concavity_worst", "Concave.points_worst", "Symmetry_worst", "Fractal_dimension_worst"), stringsAsFactors = T)
str(breast_data)
```

Los atributos se calculan a partir de una imagen digitalizada de una masa mamaria. Describen características de los núcleos celulares presentes en la imagen. Como se puede observar existen 569 registros con 32 variables, de las cuales el atributo **Diagnosis** es la variable objetivo. De cada célula se obtienen 10 características, existiendo 3 datos para cada una (con el sufijo __mean__, __se__ y __worst__). Estas son:

**Radius**: media de las distancias del centro a los puntos del perímetro de la célula. Compuesta por los atributos **Radius_mean**, **Radius_se** y **Radius_worst**.  
**Texture**: desviación estándar de los valores de la escala de grises. Compuesta por los atributos **Texture_mean**, **Texture_se** y **Texture_worst**.  
**Perimeter**: perímetro de la célula. Compuesta por los atributos **Perimeter_mean**, **Perimeter_se** y **Perimeter_worst**.  
**Area**: área de la célula. Compuesta por los atributos **Area_mean**, **Area_se** y **Area_worst**.  
**Smothness**: variación local de las longitudes de los radios. Compuesta por los atributos **Smothness_mean**, **Smothness_se** y **Smothness_worst**.  
**Compactness**: perimeter^2 / area - 1.0. Compuesta por los atributos **Compactness_mean**, **Compactness_se** y **Compactness_worst**.  
**Concavity**: gravedad de las partes cóncavas del contorno. Compuesta por los atributos **Concavity_mean**, **Concavity_se** y **Concavity_worst**.  
**Concave points**: número de porciones cóncavas del contorno. Compuesta por los atributos **Concave.points_mean**, **Concave.points_se** y **Concave.points_worst**.  
**Symmetry**: simetría de la célula. Compuesta por los atributos **Symmetry_mean**, **Symmetry_se** y **Symmetry_worst**.  
**Fractal dimension**: "aproximación al borde" - 1. Compuesta por los atributos **Fractal_dimension_mean**, **Fractal_dimension_se** y **Fractal_dimension_worst**.  

Además de las características anteriores de la células analizadas en una muestra, también se conoce:

**ID** (int): identificador de la muestra.  
**Diagnosis** (Factor): variable objetivo en la que "B" indica benignidad y "M", malignidad de la muestra.

El total de mujeres de la muestra con un diagnóstico benigno o maligno se muestra en la siguiente gráfica:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')

datos <- breast_data %>% group_by(Diagnosis) %>% summarise(Total=n()) 
ggplot(datos, aes(x = Diagnosis, y=Total, fill=Diagnosis) ) +    
  geom_bar(width = 0.9, stat="identity",              
           position = position_dodge()                
           )+  
  
  ylim(c(0,400))+
  labs(x="Diagnóstico de la paciente", y= "Frecuencia") +   
  labs(fill = "")+                                         
  
  geom_text(aes(label=Total), vjust=1.6, color="black",   
              position = position_dodge(0.9),  size=4.0
            ) +                                            
  
  theme_bw(base_size = 15) + scale_fill_hue(labels = c("B: Benigno", "M: Maligno"))


```

Los datos no están bien distribuidos ya que existe un mayor número de muestras con un valor 'B' de la variable objetivo.


******
# Integración y selección de los datos de interés a analizar
******

Los datos proceden de una única fuente de datos, por lo que no hay necesidad de intergrar datos de fuentes diferentes. 

Asimismo, después de analizar los datos se considera que hay que eliminar el atributo **ID**, ya que no aporta información para poder clasificar una muestra de datos como posible benigna o maligna. Así, el nuevo _dataset_ sería el siguiente:

```{r  message= FALSE, warning=FALSE}

breast_data_def <- breast_data[c(2:32)]

```

El conjunto de datos tendrá 31 variables, aunque posteriormente se hará un análisis más profundo para disminuir la dimiensión.


******
# Limpieza de los datos
******

## Identificación y tratamiento de elementos vacíos, ceros o nulos

Analizando los datos:

```{r message= FALSE, warning=FALSE}
summary(breast_data_def)
```
Se puede observar que no hay datos perdidos (no hay valores NA) y que hay una serie de atributos que tienen valor 0 en alguna muestra, pero todos tienen que ver con la concavidad de la célula, por lo que se asume que son valores correctos.

En caso de que hubiera elementos nulos se puede, entre otros: 

* Eliminar los registros donde existan elementos nulos: solo debe utilizarse cuando el proceso de recogida de datos es aleatorio (en otro caso, produce un sesgo) y si hay datos suficientes (si no, puede afectar a la representación de la muestra).
* Cambiar los valores nulos por la media, mediana o moda de valores de ese atributo: distorsiona la verdadera distribución de la variable y la correlación entre variables, así como dificulta la estimación de la varianza.


## Identificación y tratamiento de valores extremos

En la siguiente imagen se pueden observar los valores extremos (__outliers__) de una serie de atributos del conjunto de datos:

```{r message= FALSE, warning=FALSE}

boxplot(scale(breast_data_def[,c(8, 15, 24, 28)]), xlab ="variables", cex.axis=0.8, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
```

Se puede observar que hay datos atípicos en los atributos analizados. Si los valores atípicos corresponden con tumores malignos, pueden ser valores correctos y no errores en las medidas, sin embargo, cuando los valores atípicos están en en muestras benignas, se podrían corregir. En un apartado posterior se analizará si corresponden con muestras malignas o no y si no lo son, se tratarán estos valores.


******
# Análisis de los datos
******

## Planificación de los análisis a aplicar

Inicialmente se analizará la correlación total (sin contar con la variable objetivo), para comprobar si se pueden eliminar variables debido a la alta correlación entre ellas. Así:


```{r message= FALSE, warning=FALSE}
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matriz de los p-values de la correlación
p.mat_total <- cor.mtest(breast_data_def[c(2:31)])

M_total <- cor(breast_data_def[c(2:31)])

corrplot(M_total, type="upper", order="hclust", method="circle",
         p.mat = p.mat_total, sig.level = 0.05, insig = "blank", tl.cex  = 0.65)
```

Revisando la información de correlación, se puede ver que **Perimeter_worst**, **Area_mean**, **Radius_mean**, **Perimeter_mean**, **Area_worst** y **Radius_worst** tienen una correlación de 1. Asimismo, **Area_se**, **Radius_se** y **Permiter_se** también tienen una correlación de 1. Lo mismo ocurre entre **Concavity_mean**, **Concave.points_worst** y **Concave.points_mean**. En todos los casos se puede eliminar todas ellas, menos una de cada grupo. Así: 

```{r message= FALSE, warning=FALSE}

d_num <- as.numeric(breast_data_def[,1]) 
col_eliminar <- c("Area_mean", "Radius_mean", "Perimeter_mean", "Area_worst", "Radius_worst", "Radius_se", "Perimeter_se", "Concave.points_worst", "Concave.points_mean")

breast_data_def_corr <- breast_data_def[, !(names(breast_data_def) %in% col_eliminar)]

```

La nueva dimensión del conjunto de datos es de 22 variables.

A continuación, se seleccionan los grupos dentro del conjunto de datos que pueden resultar de interés para analizar y/o comparar. Sin embargo, en un análisis posterior se verá que no todos los atributos se van a utilizar. Los datos se van a dividir en tres grandes grupos: media (__mean__), error estándar (__se__) y peor (__worst__):

```{r message= FALSE, warning=FALSE}

breast_data_groups <- breast_data_def_corr

# Agrupación mean
breast_data_groups.mean <- breast_data_groups[c('Texture_mean', 'Smoothness_mean', 'Compactness_mean', 'Concavity_mean', 'Symmetry_mean', 'Fractal_dimension_mean')]
# Agrupación se
breast_data_groups.se <- breast_data_groups[c('Texture_se', 'Area_se', 'Smoothness_se', 'Compactness_se', 'Concavity_se', 'Concave.points_se', 'Symmetry_se', 'Fractal_dimension_se')]
# Agrupación worst
breast_data_groups.worst <- breast_data_groups[c('Texture_worst', 'Perimeter_worst', 'Smoothness_worst', 'Compactness_worst', 'Concavity_worst', 'Symmetry_worst', 'Fractal_dimension_worst')]
```

Se va a analizar la correlación entre las variables de cada grupo. Para el grupo __mean__ se tiene la siguiente matriz de correlación:

```{r  message= FALSE, warning=FALSE}
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

# matriz de los p-values de la correlación
p.mat_mean <- cor.mtest(breast_data_groups.mean)

M_mean <- cor(breast_data_groups.mean)

corrplot(M_mean, type="upper", order="hclust", method="circle",
         p.mat = p.mat_mean, sig.level = 0.05, insig = "blank", tl.cex  = 0.65)


```

A partir del análisis de correlación, se puede eliminar **Compactness_mean**, ya que tiene una correlación con **Concavity_mean** cercana a 1. Para el grupo __se__ se tiene la siguiente correlación:


```{r  message= FALSE, warning=FALSE}
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

# matriz de los p-values de la correlación
p.mat_se <- cor.mtest(breast_data_groups.se)

M_se <- cor(breast_data_groups.se)

corrplot(M_se, type="upper", order="hclust", method="circle",
         p.mat = p.mat_se, sig.level = 0.05, insig = "blank", tl.cex  = 0.65)
```

En este caso no se elimina ninguna variable. Para el grupo __worst__ se tiene la siguiente correlación:


```{r  message= FALSE, warning=FALSE}
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

# matriz de los p-values de la correlación
p.mat_worst <- cor.mtest(breast_data_groups.worst)

M_worst <- cor(breast_data_groups.worst)

corrplot(M_worst, type="upper", order="hclust", method="circle",
         p.mat = p.mat_worst, sig.level = 0.05, insig = "blank", tl.cex  = 0.65)
```

A partir del análisis de correlación, se puede eliminar **Compactness_worst**, ya que tiene una correlación con **Concavity_worst** cercana a 1.

Por tanto, el nuevo conjunto de datos será:

```{r message= FALSE, warning=FALSE}

breast_data_def_grouping <- breast_data_groups[c('Diagnosis', 'Texture_mean', 'Smoothness_mean', 'Concavity_mean', 'Symmetry_mean', 'Fractal_dimension_mean', 'Texture_se', 'Area_se', 'Smoothness_se', 'Compactness_se', 'Concavity_se', 'Concave.points_se', 'Symmetry_se', 'Fractal_dimension_se', 'Texture_worst', 'Perimeter_worst', 'Smoothness_worst', 'Concavity_worst', 'Symmetry_worst', 'Fractal_dimension_worst')]

dim(breast_data_def_grouping)

```

Finalmente, el conjunto de datos tendrá 20 atributos sobre los que se hará el análisis posterior, que podrá modificar la dimensión.

En apartados anteriores se comprobó que los valores de la mediana de los atributos están muy cerca de la mitad de la caja, indicando que los valores de los datos son más o menos simétricos. En el análisis descriptivo que se realizó en el apartado "Identificación y tratamiento de elementos vacíos, ceros o nulos" se puede comprobar que los atributos no están todos en el mismo rango, existiendo en algunos de ellos, una gran diferencia entre los valores mínimo y máximo.

En los siguientes apartados se hará un estudio de la normalidad y homogeneidad de la varianza, así como  se planterán algunas pruebas estadísticas.


## Normalidad y homogeneidad de la varianza

Para comprobar cuales de las variables cuantitativas de las que disponemos sigue una distribución normal se empleará la prueba de normalidad de **Shapiro-Wilk**. Si la variable tiene un p-valor superior a 0.05 se considera que sigue una distribucion normal:  

```{r message= FALSE, warning=FALSE}

alpha = 0.05
col.names = colnames(breast_data_def_grouping)

for (i in 1:ncol(breast_data_def_grouping)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n\n")
  if (is.integer(breast_data_def_grouping[,i]) | is.numeric(breast_data_def_grouping[,i])) {
    p_val = shapiro.test(breast_data_def_grouping[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i])
      if (i < ncol(breast_data_def_grouping)) cat(", ")
      if (i %% 3 == 0) cat("\n")
    }
  }
}

```

Se puede observar que todos los atributos no siguen una distribución normal. En cuanto a la homogeneidad de la varianza, se va a utilizar el test de **Fligner-Killeen**, debido a ese mismo hecho. Para ello, se van a comparar las varianzas para un diagnóstico benigno y maligno de los distintos atributos. Así:

```{r  message= FALSE, warning=FALSE}

alpha = 0.05
col.names = colnames(breast_data_def_grouping)
datosB <- filter(breast_data_def_grouping, breast_data_def_grouping$Diagnosis=="B")
datosM <- filter(breast_data_def_grouping, breast_data_def_grouping$Diagnosis=="M")

for (i in 2:ncol(breast_data_def_grouping)) {
  if (i == 2) cat("Los siguientes atributos presenta varianzas estadísticamente diferentes para los dos grupos de la variable objetivo:\n\n")
  a <- datosB[,i]
  b <- datosM[,i]
  p_val <- fligner.test(x=list(a,b))$p.value
  if (p_val < alpha) 
        cat(col.names[i], "\n")
}

```

Por ejemplo, si analizamos gráficamente la relación del atributo **Perimeter_worst** con la variable objetivo:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(data=breast_data_def_grouping,aes(x=Diagnosis,y=Perimeter_worst,fill=Diagnosis))+geom_boxplot()+ggtitle("Peor perímetro de célula para diagnóstico Benigno vs Maligno") 
```

Se observa cómo la varianza es mayor en los casos de malignidad, aunque la mediana está centrada en ambos diagnósticos. Esto también ocurre con el resto de las variables que posteriormente se seleccionarán para la generación de los clasificadores.

Por tanto, del análisis anterior se puede ver que en el conjunto de datos, los atributos no siguen una distribución normal y 10 de ellos no presentan igualdad de varianza respecto a la variable objetivo.


## Pruebas estadísticas

Por tanto:

**¿Qué atributos tienen una mayor relación con la posibilidad de tener un tumor benigno o maligno?**

Puesto que las variables no se ajustan a una distribucion normal, se empleará el coeficiente de correlación de **Spearman** para comprobar qué variables muestran una mayor relación con el tipo de tumor (benigno o maligno): 

```{r message= FALSE, warning=FALSE}

corr_matrix <- matrix(nc = 2, nr = 0)
colnames(corr_matrix) <- c("estimate", "p-value")
# Calcular el coeficiente de correlación para cada variable cuantitativa
# con respecto al campo "Diagnosis"
for (i in 2:(ncol(breast_data_def_grouping))) {
  if (is.integer(breast_data_def_grouping[,i]) | is.numeric(breast_data_def_grouping[,i])) {
    spearman_test = cor.test(breast_data_def_grouping[,i], as.numeric(breast_data_def_grouping[,1]), method = "spearman",exact=FALSE)
    corr_coef = spearman_test$estimate
    p_val = spearman_test$p.value
    # Se añade la fila a la matriz
    pair = matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(breast_data_def_grouping)[i]
  }
}

cat("Se ordenan los valores en base a su correlación, para conocer qué variables se correlacionan más con el diagnóstico: \n")
corr_matrix[sort(abs(corr_matrix[,1]),decreasing=T,index.return=T)[[2]],]

```

Se aprecia que las variables que más influyen son: **Perimeter_worst**, **Concavity_mean**, **Area_se** y **Concavity_worst** (todas por encima del 50% de estimación) que, además, están en el listado de atributos que presentan varianzas estadísticamente diferentes para los dos grupos de la variable objetivo (la diferencia de comportamiento respecto a los valores de la variable objetivo se mostró gráficamente para algunos de ellos). 

Por otro lado:

**¿Los valores __outliers__ son errores o corresponden con tumores malignos?**

Para comprobar esta hipótesis, que se planteó anteriormente, se empleará la columna **Perimeter_worst** puesto que es la que mayor correlación presenta con la variable objetivo, para confirmar o descartar esta hipótesis a través del test de **Mann-Whitney** (contrasta si dos muestras proceden de poblaciones equidistribuidas, es decir, comprueba que los valores de una población no tienden a ser mayores que los de otra), puesto que los valores no siguen una distribucion normal y el número de muestras es pequeño.


```{r message= FALSE, warning=FALSE}

# primer grupo de muestras: conjunto de datos con los registros que tienen los outliers de Perimeter_worst
out_perimeter_worst <- boxplot.stats(breast_data_def_grouping$Perimeter_worst)$out
out_perimeter_worst_ind <- which(breast_data_def_grouping$Perimeter_worst %in% out_perimeter_worst)
out_perimeter_diagnosis <- breast_data_def_grouping[out_perimeter_worst_ind, ]

# segundo grupo de muestras: conjunto de datos con los registros que NO tienen los outliers de Perimeter_worst
in_perimeter_worst <- subset(breast_data_def_grouping$Perimeter_worst, !(breast_data_def_grouping$Perimeter_worst %in% out_perimeter_diagnosis$Perimeter_worst))
in_perimeter_worst_ind <- which(breast_data_def_grouping$Perimeter_worst %in% in_perimeter_worst)
in_perimeter_diagnosis <- breast_data_def_grouping[in_perimeter_worst_ind, ]

wilcox.test(as.numeric(out_perimeter_diagnosis$Diagnosis), as.numeric(in_perimeter_diagnosis$Diagnosis),  alternative = "g", mu = 0)


```
Al ser __p_value__ menor que el valor de la significancia (0.05), se rechaza la hipótesis nula, por tanto, la media del primer grupo de muestras  debe ser mayor (alternative es 'g' o 'greater') a la media del segundo grupo de muestras y si el primer grupo de muestras pertenece a tumores malignos (valor 2), tiene un valor asignado mayor al que tendrían el otro grupo en el que habría tumores benignos (valor 1) y malignos (valor 2). Esto quiere decir que podemos afirmar que el primer grupo de muestras está formado por muestras que corresponden con tumores malignos, es decir, los valores __outliers__ (que forman completamente ese grupo) están en muestras con tumores malignos, luego se considerarán valores válidos. En el apartado final sobre resultados, se presenta de forma gráfica cómo los valores __outliers__ pertenecen a muestras de tumores malignos.

En función de los análisis anteriores, se seleccionan las variables del conjunto de datos teniendo en cuenta cuáles de ellas están más correladas con la variable objetivo. Estas son:  **Perimeter_worst**, **Concavity_mean**, **Area_se**, **Concavity_worst** y la variable objetivo **Diagnosis**. Así:

```{r message= FALSE, warning=FALSE}

# se seleccionan las variables mejor correladas con la variable objetivo del grupo inicial
data_selected <- breast_data_def_grouping[c('Diagnosis', 'Perimeter_worst', 'Concavity_worst', 'Concavity_mean', 'Area_se')]

```

Antes de empezar el análisis y tal y como se indicó anteriormente, se va a eliminar las anomalías en las muestras de tumores benignos sustituyéndolas por la **media** de los valores de las mismas características, sin embargo, previamente hay que descubrir los verdaderos _outliers_ de esas muestras. Para encontrar estos valores se van a analizar el primer y tercer cuartil de cada variable seleccionada (ya que entre esos dos valores o rango intercuantílico, está el 50% de todos los valores obtenidos en el estudio). Así:

```
| variable        |    Q1   |    Q3   | IRQ=Q3-Q1 | US:Q3+1,5XIQR | UI:Q1-1,5XIQR |
|-----------------|---------|---------|-----------|---------------|---------------|
| Perimeter_worst |  84,11  |  125,40 |   41,29   |    187,335    |     22,175    |
| Concavity_mean  | 0,02956 |  0,1307 |  0,10114  |    0,24281    |    -0,12215   |
| Area_se         |  17,85  |  45,19  |   27,34   |     86,2      |     -23,16    |
| Concavity_worst |  0,1145 |  0,3829 |  0,2684   |    0,7855     |    -0,2881    |
```

Por tanto, los valores que estén fuera de los rangos anteriores (UI..US) se modificarán para ser sustituidos por la **media** de los datos de las mismas características. Los valores atípicos que estén dentro del rango, se considerarán valores válidos. Así: 

```{r message= FALSE, warning=FALSE}

data_selected_B <- filter(data_selected, data_selected$Diagnosis == 'B')
boxplot(scale(data_selected_B[2:5]), xlab ="atributos", cex.axis=0.8, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías (antes de la eliminación)")

for (i in 1:nrow(data_selected)) {
  if (data_selected[i,1] == 'B') {
    if (data_selected[i,2] < 22.175 | data_selected[i,2] > 187.335)
      data_selected[i,2] <- mean(data_selected_B$Perimeter_worst)
    if (data_selected[i,4] < -0.12215 | data_selected[i,4] > 0.24281)
      data_selected[i,4] <- mean(data_selected_B$Concavity_mean)
    if (data_selected[i,5] < -23.16 | data_selected[i,5] > 86.2)
      data_selected[i,5] <- mean(data_selected_B$Area_se)
    if (data_selected[i,3] < -0.2881 | data_selected[i,3] > 0.7855)
      data_selected[i,3] <- mean(data_selected_B$Concavity_worst)
  }  
}
data_selected_B <- filter(data_selected, data_selected$Diagnosis == 'B')
boxplot(scale(data_selected_B[2:5]), xlab ="atributos", cex.axis=0.8, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías (después de la eliminación)")

```

Una vez eliminados los datos __outliers__ de las muestras de tumores benignos, se genera el archivo de salida con los datos a analizar:


```{r message= FALSE, warning=FALSE}

data_to_analyze <- data_selected

# se genera el archivo de salida
write.csv(data_to_analyze, "TCVD_CancerWisconsi.csv")

```

A continuación se van a utilizar diferentes métodos de clasificación usando los atributos indicados anteriormente del conjunto de datos y se evaluará la calidad de los método usados mediante Validación Cruzada o K-fold Cross Validation. 

Inicialmente se van a crear los grupos de entrenamiento y test, el primero con 2/3 de los datos y el segundo con 1/3 de los datos originales:

```{r message= FALSE, warning=FALSE}
if (!require('caTools')) install.packages('caTools'); library('caTools')

# se dividen en grupo de entrenamiento y grupo de test
set.seed(123)
split <- sample.split(data_to_analyze$Diagnosis, SplitRatio = 0.75)
training_set <- subset(data_to_analyze, split == TRUE)
test_set <- subset(data_to_analyze, split == FALSE)
dim(training_set)
dim(test_set)

```

La distribución de muestras malignas y benignas debe ser simétrica en ambos conjuntos:

```{r message= FALSE, warning=FALSE}
cat("Porcentaje de muestras benignas y malignas en el conjunto de entrenamiento: ")
prop.table(table(training_set$Diagnosis))
cat("\nPorcentaje de muestras benignas y malignas en el conjunto de test: ")
prop.table(table(test_set$Diagnosis))
```

### Modelo de Regresión Logística

La **Regresión Logística** calcula las probabilidades de ocurrencia de alguna de las clases del modelo a partir del uso de la función logística. No requiere de ciertas condiciones como linealidad, normalidad y homocedasticidad. Inicialmente se entrena el modelo y se observan los datos estadísticos:


```{r message= FALSE, warning=FALSE}
if (!require('stats')) install.packages('stats'); library('stats')

clasificadorRL <- glm(as.factor(Diagnosis) ~ ., family = binomial, data = training_set)

```

Una vez que el clasificador está entrenado, se puede usar para predecir el resultado. Ya que la regresión logística ofrece como resultado las probabilidades de ocurrencia de cada clase, se va a tomar como umbral el valor de 0.5, de modo que cualquier valor por encima de esa probabilidad se tome como 1 "tumor benigno", y cualquier valor por debajo como 0 como "tumor maligno":


```{r message= FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')

pred_train_RL <- predict(clasificadorRL, type = 'response', ndata = training_set)
pred_train_RL <- ifelse(pred_train_RL > 0.5, 1, 0)
pred_train_RL <- factor(pred_train_RL, levels = c("0", "1"), labels = c("B", "M"))

```

Analizando la matriz de confusión para evaluar la calidad de la predicción:


```{r message= FALSE, warning=FALSE}
matrizConfusion_train_RL <- confusionMatrix(data=pred_train_RL, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))

matrizConfusion_train_RL

```

Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente 408 (259 verdaderos positivos y 149 verdaderos negativos). Asimismo hay 9 falsos negativos (es decir, 9 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 10 falsos positivos (es decir, 10 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tiene una precisión de 95% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 97% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:


```{r message= FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')

pred_test_RL <- predict(clasificadorRL, type = 'response', newdata = test_set)
pred_test_RL <- ifelse(pred_test_RL > 0.5, 1, 0)
pred_test_RL <- factor(pred_test_RL, levels = c("0", "1"), labels = c("B", "M"))

matrizConfusion_test_RL <- confusionMatrix(data=pred_test_RL, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))

matrizConfusion_test_RL

```

Se observa que de 142 mujeres del grupo de test, con el modelo usado se han clasificado correctamente 134 (86 verdaderos positivos y 48 verdaderos negativos). Asimismo hay 3 falsos negativos (es decir, 3 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 5 falsos positivos (es decir, 5 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tienen una precisión de 94% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 97% (verdaderos positivos identificados).


### Modelo Naive Bayes
La clasificacion **naive bayes** se basa en el teorema de **bayes** para clasificar. Inicialmente se entrena el modelo y se observan los datos estadísticos:

```{r  message= FALSE, warning=FALSE}
if (!require('e1071')) install.packages('e1071'); library('e1071')

clasificadorBayes <- naiveBayes(Diagnosis ~ ., data = training_set)

```

Analizando el modelo sobre el conjunto de entrenamiento:

```{r message= FALSE, warning=FALSE}

pred_train_bayes <- predict(clasificadorBayes, newdata = training_set)

matrizConfusion_bayes <- confusionMatrix(data=pred_train_bayes, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_bayes

```


Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 401. El clasificador tiene una precisión del 94% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 96% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:

```{r message= FALSE, warning=FALSE}

pred_test_bayes <- predict(clasificadorBayes, newdata = test_set)
matrizConfusion_bayes <- confusionMatrix(data=pred_test_bayes, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_bayes

```

Se observa que de 142 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 129. Ha habido 6 falsos positivos y 7 falsos negativos. El clasificador tienen una precisión de 91% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 92% (verdaderos positivos identificados).

### Modelo de Árbol de Decisión

La clasificacion **Decision Tree** se basa en reglas lógicas a partir de los datos de entrada. Inicialmente se entrena el modelo y se observan los datos estadísticos:

```{r message= FALSE, warning=FALSE}
if (!require('rpart')) install.packages('rpart'); library('rpart')

clasificadorDT  <- rpart(Diagnosis ~ ., data = training_set)

```

Analizando el modelo sobre el conjunto de entrenamiento:

```{r message= FALSE, warning=FALSE}

pred_train_tree <- predict(clasificadorDT, newdata = training_set)

pred_df <- data.frame(pred_train_tree)
fact = cut(pred_df$B,2,labels=c("M","B"))
matrizConfusion_tree <- confusionMatrix(data=fact, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_tree

```

Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 408. El clasificador tiene una precisión de 95% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 96% (verdaderos positivos identificados).

Si se hace la misma prueba sobre el grupo de test:

```{r message= FALSE, warning=FALSE}

pred_test_tree <- predict(clasificadorDT, newdata = test_set)
pred_df <- data.frame(pred_test_tree)
fact = cut(pred_df$B,2,labels=c("M","B"))
matrizConfusion_tree <- confusionMatrix(data=fact, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_tree

```


Se observa que de 142 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 127. Ha habido 4 falsos positivos y 11 falsos negativos. El clasificador tienen una precisión de 89% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 88% (verdaderos positivos identificados).


### Modelo Random Forests

La clasificación **Random Forests** construye al azar una gran cantidad de árboles de decisión (__ntree__ en la función usada) sobre un mismo conjunto de datos, y la decisión final de la clasificación es tomada a partir de calcular el voto de la mayoría de las predicciones ofrecidas por cada uno de los árboles que conforman el bosque.

```{r message= FALSE, warning=FALSE}
if (!require('randomForest')) install.packages('randomForest'); library('randomForest')

clasificadorRF <- randomForest(Diagnosis ~ ., data = training_set, ntree = 250)

```

Analizando el modelo sobre el conjunto de entrenamiento:


```{r message= FALSE, warning=FALSE}
pred_train_RF <- predict(clasificadorRF, newdata = training_set)
matrizConfusion_train_RF <- confusionMatrix(data=pred_train_RF, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_train_RF

```

Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente todas ellas. El clasificador tienen una precisión de 100% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 100% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:

```{r message= FALSE, warning=FALSE}
pred_test_RF <- predict(clasificadorRF, newdata = test_set)
matrizConfusion_test_RF <- confusionMatrix(data=pred_test_RF, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_test_RF

```

Se observa que de 142 mujeres del grupo de test, con el modelo usado se han clasificado correctamente 129 (81 verdaderos positivos y 48 verdaderos negativos). Asimismo hay 8 falsos negativos (es decir, 8 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 5 falsos positivos (es decir, 5 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tienen una precisión de 91% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 91% (verdaderos positivos identificados).


### Comparación de los modelos usando K-Fold Cross Validation

A continuación se comparan los resultados de los modelos anteriores usando K-Fold Cross Validation. Se van a usar 10 subconjuntos:

```{r message= FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')

folds <- createFolds(training_set$Diagnosis, k = 10)

```

```{r  message= FALSE, warning=FALSE}
if (!require('class')) install.packages('class'); library('class')
if (!require('rpart')) install.packages('rpart'); library('rpart')
if (!require('randomForest')) install.packages('randomForest'); library('randomForest')

# Regresion Logistica
cvRegresionLogistica <- lapply(folds, function(x) {
    training_fold <- training_set[-x, ]
    test_fold <- training_set[x, ]
    clasificadorRL <- glm(Diagnosis ~ ., family = binomial, data = training_fold)
    y_pred <- predict(clasificadorRL, type = 'response', newdata = test_fold)
    y_pred <- ifelse(y_pred > 0.5, 1, 0)
    y_pred <- factor(y_pred, levels = c("0", "1"), labels = c("B", "M"))
    cm <- table(test_fold$Diagnosis, y_pred)
    precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
    return(precision)
})
precisionRegresionLogistica <- mean(as.numeric(cvRegresionLogistica))

# Naive-Bayes
cvNaiveBayes <- lapply(folds, function(x){
  training_fold <- training_set[-x, ]
  test_fold <- training_set[x, ]
  clasificadorNB <- naiveBayes(Diagnosis ~ ., data = training_fold)
  y_pred <- predict(clasificadorNB, newdata = test_fold)
  cm <- table(test_fold$Diagnosis, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
precisionNaiveBayes <- mean(as.numeric(cvNaiveBayes))

# Árbol de decisión
cvDecisionTree <- lapply(folds, function(x){
  training_fold <- training_set[-x, ]
  test_fold <- training_set[x, ]
  clasificadorDT <- rpart(Diagnosis ~ ., data = training_fold)
  y_pred <- predict(clasificadorDT, newdata = test_fold, type = 'class')
  cm <- table(test_fold$Diagnosis, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
precisionDecisionTree <- mean(as.numeric(cvDecisionTree))

# Random Forest
cvRandomForest <- lapply(folds, function(x){
  training_fold <- training_set[-x, ]
  test_fold <- training_set[x, ]
  clasificadorRF <- randomForest(Diagnosis ~ ., data = training_fold, ntree = 250)
  y_pred <- predict(clasificadorRF, newdata = test_fold)
  cm <- table(test_fold$Diagnosis, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  return(precision)
})
precisionRandomForest <- mean(as.numeric(cvRandomForest))

precisionRegresionLogistica
precisionNaiveBayes
precisionDecisionTree
precisionRandomForest

```

Observándose que el mejor clasificador es el modelo de **Regresión Logística** con un 95% de precisión (mayor que en la prueba previa), frente a un 93% del modelo **Árbol de decisión**. 


******
# Representación de los resultados
******

A continuación se van a presentar distintos gráficos estadísticos que demuestran las pruebas estadísticas realizadas. Por un lado se comprobará que los datos seleccionados y usados en los clasificadores tienen calidad suficiente para detectar, a partir de una muestra, si un tumor en la mama es benigno o maligno y por otro se comprobará si los __outliers__ de las variables seleccionadas coinciden con muestras de tumores malignos. 

Así, para comprobar la calidad de los atributos seleccionados se va a presentar el histograma de los mismos junto con la media de cada uno. En las gráficas se puede comprobar que las mujeres con tumores benignos tienen resultados mayoritariamente por debajo de la media mientras que las que tienen tumores malignos están mayoritariamente por encima de la media:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data, aes(x = Perimeter_worst)) + geom_histogram(binwidth = 10, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Perímetro peor para diagnósticos Benignos vs Malignos") +labs(x="Perímetro peor", y="Número de mujeres") +
  geom_vline(aes(xintercept = mean(Perimeter_worst), colour="media"),
              linetype = "dashed",
              size = 1) 

ggplot(breast_data, aes(x = Concavity_mean)) + geom_histogram(binwidth = 0.01, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Media de la concavidad para diagnósticos Benignos vs Malignos") +labs(x="Media de la concavidad", y="Número de mujeres") +
  geom_vline(aes(xintercept = mean(Concavity_mean), colour="media"),
              linetype = "dashed",
              size = 1) 

ggplot(breast_data, aes(x = Area_se)) + geom_histogram(binwidth = 20, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Error estándar de área para diagnósticos Benignos vs Malignos") +labs(x="Error estándar de área", y="Número de mujeres") +
  geom_vline(aes(xintercept = mean(Area_se), colour="media"),
              linetype = "dashed",
              size = 1) 

ggplot(breast_data, aes(x = Concavity_worst)) + geom_histogram(binwidth = 0.05, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Peor concavidad para diagnósticos Benignos vs Malignos") +labs(x="Peor concavidad", y="Número de mujeres") +
  geom_vline(aes(xintercept = mean(Concavity_worst), colour="media"),
              linetype = "dashed",
              size = 1) 

```

Por otro lado, se va a comprobar que los __outliers__ detectados en las variables analizadas corresponden con muestras de tumores malignos:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('grid')) install.packages('grid'); library('grid')
if (!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')

grid.newpage()

out_perimeter_worst <- boxplot.stats(data_to_analyze$Perimeter_worst)$out
out_perimeter_worst_ind <- which(data_to_analyze$Perimeter_worst %in% out_perimeter_worst)
out_perimeter_diagnosis <- data_to_analyze[out_perimeter_worst_ind,]

datos_pw <- out_perimeter_diagnosis %>% group_by(Diagnosis) %>% summarise(Total=n()) 
plot1 <- ggplot(datos_pw, aes(x=Diagnosis,  y=Total, fill=Diagnosis))+ ggtitle("Outliers (Perimeter_worst)") +
  geom_bar(stat='identity') +                                         
  geom_text(aes(label=Total), vjust=1.6, color="black", position = position_dodge(0.9),  size=4.0) 

out_Concavity_mean <- boxplot.stats(data_to_analyze$Concavity_mean)$out
out_Concavity_mean_ind <- which(data_to_analyze$Concavity_mean %in% out_Concavity_mean)
out_Concavity_mean_diagnosis <- data_to_analyze[out_Concavity_mean_ind,]

datos_cm <- out_Concavity_mean_diagnosis %>% group_by(Diagnosis) %>% summarise(Total=n()) 
plot2 <- ggplot(datos_cm, aes(x=Diagnosis,  y=Total, fill=Diagnosis))+ ggtitle("Outliers (Concavity_mean)") +
  geom_bar(stat='identity') +                                         
  geom_text(aes(label=Total), vjust=1.6, color="black", position = position_dodge(0.9),  size=4.0) 

out_Area_se <- boxplot.stats(data_to_analyze$Area_se)$out
out_Area_se_ind <- which(data_to_analyze$Area_se %in% out_Area_se)
out_Area_se_diagnosis <- data_to_analyze[out_Area_se_ind,]

datos_ase <- out_Area_se_diagnosis %>% group_by(Diagnosis) %>% summarise(Total=n()) 
plot3 <- ggplot(datos_ase, aes(x=Diagnosis,  y=Total, fill=Diagnosis))+ ggtitle("Outliers (Area_se)") +
  geom_bar(stat='identity') +                                         
  geom_text(aes(label=Total), vjust=1.6, color="black", position = position_dodge(0.9),  size=4.0) 

out_Concavity_worst <- boxplot.stats(data_to_analyze$Concavity_worst)$out
out_Concavity_worst_ind <- which(data_to_analyze$Concavity_worst %in% out_Concavity_worst)
out_Concavity_worst_diagnosis <- data_to_analyze[out_Concavity_worst_ind,]

datos_cw <- out_Concavity_worst_diagnosis %>% group_by(Diagnosis) %>% summarise(Total=n()) 
plot4 <- ggplot(datos_cw, aes(x=Diagnosis,  y=Total, fill=Diagnosis))+ ggtitle("Outliers (Concavity_worst)") +
  geom_bar(stat='identity') +                                         
  geom_text(aes(label=Total), vjust=1.6, color="black", position = position_dodge(0.9),  size=4.0) 

grid.arrange(plot1, plot2, plot3, plot4, ncol=2, heights=3:2)

```

En todos los casos, los __outliers__ corresponden a "tumores malignos", una vez que se han modificado aquellos que correspondían con tumores benignos. No es aconsejable eliminar las muestras con los  valores __outliers__ de tumores malignos (ni sustituirlos por otros valores), ya que pueden ser valores correctos.


******
# Conclusiones
******

En el trabajo realizado se ha utilizado el __dataset__  **Breast Cancer Wisconsin (Diagnostic) Data Set** de UCI Machine Learning Repository que analiza la incidencia del cáncer de mama en una población de 569 mujeres. Se ha realizado un estudio del conjunto de datos para describir las distintas variables y se ha comprobado que el conjunto está limpio aunque tiene algunos __outliers__, la mayoría de los cuales se demuestra que pertenecen a muestras de tumores malignos y que, por tanto, se consideran valores correctos.

Por otro lado, se analizó la correlación de los datos del conjunto completo y agrupándolo por tipo de medidas con lo que se eliminaron una gran cantidad de variables que no aportan la suficiente información. Asimismo, se comprobó la normalidad y homocedasticidad, observando que los atributos seleccionados no siguen una distribución normal y 10 de ellos no presentan igualdad de varianza respecto a la variable objetivo. 

Asimismo, se hacen dos tipos de pruebas estadísticas: por un lado se analizaron los datos para ver qué atributos tenía más del 50% de correlación con la variable objetivo, ya que estos son los que más influyen en la benignidad o malignidad de un tumor y por otro lado, se analizó si los __outliers__ realmente correspondían a medidas correctas. El resultado de estas pruebas se demostró gráficamente en las sección "Representación de los resultados".

Con los atributos seleccionados se realizaron cuatros modelos de clasificación: **Regresión logística**, **Naive-Bayes**, **Árbol de decisión** y **Random Forests**, comprobando su calidad mediante una validación cruzada con 10 __folds__. Finalmente, se deduce que el clasificador del modelo de **Regresión logística** es el que tiene más precisión con un 95% y el modelo **Árbol de decisión** es el que tiene menos con un 93% de precisión.

