---
title: 'Tipología y ciclo de vida de los datos: Práctica 2 - Limpieza y análisis de datos'
author: "Autoras: Eva Garía Ocaña y Carmen nieves Ojeda Guerra"
date: "Enero 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Descripción del dataset
******

El _dataset_ escogido para el trabajo es el **Breast Cancer Wisconsin (Diagnostic) Data Set** de UCI Machine Learning Reposity (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) que analiza la incidencia del cáncer de mama en una población de 569 mujeres.

**Motivación:** Según la OMS, el cáncer de mama es el tipo de cáncer más común, con más de 2,2 millones de casos en 2020 y cerca de una de cada 12 mujeres enfermarán de cáncer de mama a lo largo de su vida. El cáncer de mama es la principal causa de mortalidad en las mujeres. En 2020, alrededor de 685000 mujeres fallecieron como consecuencia de esa enfermedad. Sin embargo, desde 1980 se han realizado importantes avances en el tratamiento del cáncer de mama debido a la combinación de la **detección precoz** y las terapias eficaces, basadas en cirugía, radioterapia y farmacoterapia (https://www.who.int/es/news-room/fact-sheets/detail/breast-cancer, marzo 2021). En España, según los últimos datos recogidos por el Sistema Europeo de Información del Cáncer (ECIS) de 2020, aproximadamente el 30% de los cánceres diagnosticados en mujeres se originan en la mama (https://www.geicam.org/sala-de-prensa/el-cancer-de-mama-en-espana, 2021). Una detección
temprana de la presencia de células cancerosas malignas aumenta la posibilidad de vida de las pacientes, sobre todo cuando se localiza un tumor pequeño y aún no ramificado. Para la realización de este estudio, el análisis de los datos obtenidos a partir de la información de estas células puede detectar la malignidad o benignidad de las mismas.

**Potencial analítico del conjunto de datos:** Debido a las características del conjunto de datos (atributos de los que dispone) se pueden plantear preguntas que ayuden a comprender mejor cómo afectan los factores clave en la población estudiada y analizar qué variables pueden ser decisivas a la hora de conocer si un tumor es benigno o maligno. Una medida del potencial del conjunto de datos se puede ver en la cantidad de artículos de reconocido prestigio que lo usan en sus investigaciones, como por ejemplo:

1- Chien-Hsing Chen, _A hybrid intelligent model of analyzing clinical breast cancer data using clustering techniques with feature selection_, Applied Soft Computing, Volume 20, 2014, Pages 4-14, ISSN 1568-4946, https://doi.org/10.1016/j.asoc.2013.10.024.

2- Lingxi Peng, Wenbin Chen, Wubai Zhou, Fufang Li, Jin Yang, Jiandong Zhang, _An immune-inspired semi-supervised algorithm for breast cancer diagnosis_,
Computer Methods and Programs in Biomedicine, Volume 134, 2016, Pages 259-265, ISSN 0169-2607, https://doi.org/10.1016/j.cmpb.2016.07.020.

3- Bichen Zheng, Sang Won Yoon, Sarah S. Lam, _Breast cancer diagnosis based on feature extraction using a hybrid of K-means and support vector machine algorithms_, Expert Systems with Applications, Volume 41, Issue 4, Part 1, 2014,
Pages 1476-1482, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2013.08.044.

4- S. Punitha, Thompson Stephan, Amir H. Gandomi, _A Novel Breast Cancer Diagnosis Scheme With Intelligent Feature and Parameter Selections_,
Computer Methods and Programs in Biomedicine, 2021, 106432, ISSN 0169-2607, https://doi.org/10.1016/j.cmpb.2021.106432.

Para comenzar el análisis, se carga el _dataset_ desde la fuente origen:

```{r message= FALSE, warning=FALSE}
breast_data <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", sep = ",", col.names = c("ID", "Diagnosis", "Radius_mean", "Texture_mean", "Perimeter_mean", "Area_mean", "Smoothness_mean", "Compactness_mean", "Concavity_mean", "Concave.points_mean", "Symmetry_mean", "Fractal_dimension_mean", "Radius_se", "Texture_se", "Perimeter_se", "Area_se", "Smoothness_se", "Compactness_se", "Concavity_se", "Concave.points_se", "Symmetry_se", "Fractal_dimension_se", "Radius_worst", "Texture_worst","Perimeter_worst", "Area_worst", "Smoothness_worst", "Compactness_worst", "Concavity_worst", "Concave.points_worst", "Symmetry_worst", "Fractal_dimension_worst"), stringsAsFactors = T)
str(breast_data)
```

Las características se calculan a partir de una imagen digitalizada de una masa mamaria. Describen características de los núcleos celulares presentes en la imagen. Como se puede observar existen 569 registros con 32 variables, de las cuales el atributo **Diagnosis** es la variable objetivo. De cada célula se obtienen 10 características, existiendo 3 datos para cada una. Estas son:

**Radius**: media de las distancias del centro a los puntos del perímetro de la célula. Compuesta por los atributos **Radius_mean**, **Radius_se** y **Radius_worst**.  
**Texture**: desviación estándar de los valores de la escala de grises. Compuesta por los atributos **Texture_mean**, **Texture_se** y **Texture_worst**.  
**Perimeter**: perímetro de la célula. Compuesta por los atributos **Perimeter_mean**, **Perimeter_se** y **Perimeter_worst**.  
**Area**: área de la célula. Compuesta por los atributos **Area_mean**, **Area_se** y **Area_worst**.  
**Smothness**: variación local de las longitudes de los radios. Compuesta por los atributos **Smothness_mean**, **Smothness_se** y **Smothness_worst**.  
**Compactness**: perimeter^2 / area - 1.0. Compuesta por los atributos **Compactness_mean**, **Compactness_se** y **Compactness_worst**.  
**Concavity**: gravedad de las partes cóncavas del contorno. Compuesta por los atributos **Concavity_mean**, **Concavity_se** y **Concavity_worst**.  
**Concave points**: número de porciones cóncavas del contorno. Compuesta por los atributos **Concave.points_mean**, **Concave.points_se** y **Concave.points_worst**.  
**Symmetry**: simetría de la célula. Compuesta por los atributos **Symmetry_mean**, **Symmetry_se** y **Symmetry_worst**.  
**Fractal dimension**: "aproximación al borde" - 1. Compuesta por los atributos **Fractal_dimension_mean**, **Fractal_dimension_se** y **Fractal_dimension_worst**.  

Además de las características anteriores de la células analizadas en una muestra, también se conoce:

**ID** (int): identificador de la muestra.  
**Diagnosis** (Factor): variable objetivo en la que "B" indica benignidad y "M", malignidad de la muestra.

El total de mujeres con un diagnóstico benigno o maligno se muestra en la siguiente gráfica:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')

datos <- breast_data %>% group_by(Diagnosis) %>% summarise(Total=n()) 
ggplot(datos, aes(x = Diagnosis, y=Total, fill=Diagnosis) ) +    
  geom_bar(width = 0.9, stat="identity",              
           position = position_dodge()                
           )+  
  
  ylim(c(0,400))+
  labs(x="Diagnóstico de la paciente", y= "Frecuencia") +   
  labs(fill = "")+                                         
  
  geom_text(aes(label=Total), vjust=1.6, color="black",   
              position = position_dodge(0.9),  size=4.0
            ) +                                            
  
  theme_bw(base_size = 15) + scale_fill_hue(labels = c("B: Benigno", "M: Maligno"))


```

Los datos no están bien distribuidos ya que existe un mayor número de muestras con un valor 'B' de la variable objetivo.


******
# Integración y selección de los datos de interés a analizar
******

Los datos proceden de una única fuente de datos, por lo que no hay necesidad de intergrar datos de fuentes diferentes. 

Asimismo, después de analizar los datos se considera que hay que eliminar el atributo **ID**, ya que no aporta información para poder clasificar una muestra de datos como posible benigna o maligna. Así, el nuevo _dataset_ sería el siguiente:

```{r  message= FALSE, warning=FALSE}

breast_data_def <- breast_data[c(2:32)]

```


Vamos analizar la correlación entre los atributos para comprobar si se pueden eliminar atributos del conjunto:


```{r  message= FALSE, warning=FALSE}
if (!require('corrplot')) install.packages('corrplot'); library('corrplot')
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matriz de los p-values de la correlación
p.mat <- cor.mtest(breast_data_def[c(2:31)])

```

```{r  message= FALSE, warning=FALSE}
if (!require('ggcorrplot')) install.packages('ggcorrplot'); library('ggcorrplot')

M <- cor(breast_data_def[c(2:31)])

corrplot(M, type="upper", order="hclust", method="circle",
         p.mat = p.mat, sig.level = 0.05, insig = "blank", tl.cex  = 0.65)
```

Revisando la información de correlación, se puede ver que **Area_mean**, **Radius_mean**, **Perimeter_mean**, **Area_worst**, **Radius_worst** y **Perimeter_worst** tienen una correlación de 1. Asimismo, **Area_se**, **Radius_se** y **Permiter_se** también tienen una correlación de 1. Lo mismo ocurre entre **Concave.points_worst**, **Concave.points_mean** y **Concavity_mean**. En todos los casos se puede eliminar todas ellas, menos una de cada grupo.

```{r}

d_num <- as.numeric(breast_data_def[,1]) 
col_eliminar <- c("Radius_mean", "Perimeter_mean", "Area_worst", "Radius_worst", "Radius_se", "Permiter_se", "Concave.points_worst", "Concave.points_mean")

breast_data_def_corr <- breast_data_def[, !(names(breast_data_def) %in% col_eliminar)]
dim(breast_data_def_corr)

```

Finalmente, el conjunto de datos tendrá 24 atributos sobre los que se hará el análisis posterior.

******
# Limpieza de los datos
******

## Identificación y tratamiento de elementos vacíos, ceros o nulos


Los datos están limpios y no hay valores perdidos. Si revisamos el número de elementos nulos se puede observar que no hay:

```{r message= FALSE, warning=FALSE}
sum(is.na(breast_data_def_corr))

```

En caso de que hubieran elementos nulos se puede: HABLAR UN POCO MÁS DE ESTO AL NO HABER VALORES NULOS!!!!!

* Eliminar los registros donde existan elementos nulos.
* Cambiar los valores nulos por la media de valores de ese atributo.
* Cambiar los valores nulos por la mediana de valores de ese atributo.

## Identificación y tratamiento de valores extremos

En la siguiente imagen se pueden observar los valores extremos (_outliers_) de cada atributo:

```{r message= FALSE, warning=FALSE}

boxplot(scale(breast_data_def_corr[2:5]), xlab ="variables", cex.axis=0.75, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
boxplot(scale(breast_data_def_corr[6:10]), xlab ="variables", cex.axis=0.55, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
boxplot(scale(breast_data_def_corr[11:15]), xlab ="variables", cex.axis=0.75, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
boxplot(scale(breast_data_def_corr[16:20]), xlab ="variables", cex.axis=0.60, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
boxplot(scale(breast_data_def_corr[21:23]), xlab ="variables", cex.axis=0.75, ylab = "Rango de Valores", col="blue", main="Información sobre anomalías y valores extremos")
```

Se puede observar que en todas los diagramas hay datos atípicos, lo que no quiere decir que sean erróneos.


******
# Análisis de los datos
******

## Planificación de los análisis a aplicar

A continuación se va a realizar el análisis descriptivo, estadístico y de supervivencia de los datos. En el primero de ellos se van a analizar la media, mediana y desviación estándar de las muestras. En las gráficos de cajas presentados anteriormente, se puede apreciar que los valores de la mediana de los atributos están muy cerca de la mitad de la caja, indicando que los valores de los datos son más o menos simétricos. Asimismo, se presentan las medias, medianas e información de os cuartiles de cada  atributo:

```{r message= FALSE, warning=FALSE}
summary(breast_data_def_corr)

```

El análisis estadístico inferencial tiene por objetivo modelar los datos a través de una distribución conocida. Partiendo de la premisa que el conjunto de datos estudiado representa una fracción de la totalidad de una población, su objetivo es inferir cómo es esa población, asumiendo un grado de error en las estimaciones por el hecho de disponer de una muestra reducida de los datos. En el siguiente subapartado se comprobará la normalidad y homogeneidad de la varianza.


## Normalidad y homogeneidad de la varianza

Para comprobar cuales de las variables cuantitativas de las que disponemos sigue una distribución normal se empleará la prueba de normalidad de **Shapiro-Wilk**. Si la variable tiene un p-valor superior a 0.05 se considera que sigue una distribucion normal:  

```{r message= FALSE, warning=FALSE}

alpha = 0.05
col.names = colnames(breast_data_def_corr)

for (i in 1:ncol(breast_data_def_corr)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n\n")
    if (is.integer(breast_data_def_corr[,i]) | is.numeric(breast_data_def_corr[,i])) {
      p_val = shapiro.test(breast_data_def_corr[,i])$p.value
      if (p_val < alpha) {
        cat(col.names[i])
        
        if (i < ncol(breast_data_def_corr)) cat(", ")
        if (i %% 3 == 0) cat("\n")
    }
  }
}

```

Se puede observar que la mayoría de los atributos no sigue una distribución normal. En cuanto a la homogeneidad de la varianza, se va a utilizar el test de **Fligner-Killeen**, debido a ese mismo hecho. Para ello, se van a comparar las varianzas para un diagnóstico benigno y maligno de los distintos atributos. Así:

```{r  message= FALSE, warning=FALSE}

alpha = 0.05
col.names = colnames(breast_data_def_corr)
datosB <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis=="B")
datosM <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis=="M")

for (i in 2:ncol(breast_data_def_corr)) {
  if (i == 2) cat("Los siguientes atributos presenta varianzas estadísticamente diferentes para los dos grupos de la variable objetivo:\n\n")
  a <- datosB[,i]
  b <- datosM[,i]
  p_val <- fligner.test(x=list(a,b))$p.value
  if (p_val < alpha) 
        cat(col.names[i], "\n")
}

```

Por ejemplo, si analizamos gráficamente la relación del atributo **Area_mean** con la variable objetivo:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(data=breast_data_def_corr,aes(x=Diagnosis,y=Area_mean,fill=Diagnosis))+geom_boxplot()+ggtitle("Media del área diagnóstico Benigno vs Maligno") 
```

Se observa cómo la varianza es mayor en los casos de malignidad, aunque la mediana está centrada en ambos diagnósticos. Existen algunos valores atípicos.

Si analizamos gráficamente la relación del atributo **Concavity_mean** con la variable objetivo:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(data=breast_data_def_corr,aes(x=Diagnosis,y=Concavity_mean,fill=Diagnosis))+geom_boxplot()+ggtitle("Media de la concavidad diagnóstico Benigno vs Maligno") 
```

También se observa cómo la varianza es mayor en los casos de malignidad, aunque la mediana está centrada en ambos diagnósticos. Existen muchos valores atípicos (mayores en el caso de benignidad, que pueden corresponder con errores en las medidas).

Si por ejemplo comprobamos un atributo que no está en la lista anterior, como **Texture_mean**:


```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(data=breast_data_def_corr,aes(x=Diagnosis,y=Texture_mean,fill=Diagnosis))+geom_boxplot()+ggtitle("Media de la textura diagnóstico Benigno vs Maligno") 
```

Se puede ver como la varianza es similar en ambos casos del diagnóstico. También se observa que hay valores atípicos.


## Pruebas estadísticas

Puesto que las variables no se ajustan a una distribucion normal, se empleara el coecifiente de correlacion de **Spearman** para comprobar qué variables muestran una mayor relación con el tipo de tumor. 

```{r message= FALSE, warning=FALSE}

corr_matrix <- matrix(nc = 2, nr = 0)
colnames(corr_matrix) <- c("estimate", "p-value")
# Calcular el coeficiente de correlación para cada variable cuantitativa
# con respecto al campo "Diagnosis"
for (i in 2:(ncol(breast_data_def_corr))) {
  if (is.integer(breast_data_def_corr[,i]) | is.numeric(breast_data_def_corr[,i])) {
    spearman_test = cor.test(breast_data_def_corr[,i], as.numeric(breast_data_def_corr[,1]),
    method = "spearman",exact=FALSE)
    corr_coef = spearman_test$estimate
    p_val = spearman_test$p.value
    # Se añade la fila a la matriz
    pair = matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(breast_data_def_corr)[i]
  }
}

cat("Se ordenan los valores en base a su correlación, para conocer qué variables se correlacionan más con el diagnóstico: \n")
corr_matrix[sort(abs(corr_matrix[,1]),decreasing=T,index.return=T)[[2]],]

```

Se aprecia que las variables que más influyen son **Perimeter_worst**, **Area_mean**, **Concavity_mean**, **Area_se** y **Concavity_worst**, que, además, están en el listado de atributos que presentan varianzas estadísticamente diferentes para los dos grupos de la variable objetivo (la diferencia de comportamiento respecto a los valores de la variable objetivo se mostró gráficamente para algunos de ellos).


------------------------------------------------------------------------------------------------------------------------

Asimismo, anteriormente se ha sugerido la hipótesis de que los valores extremos indican tumores malignos. Se empleará la columna **Perimeter_worst** puesto que es la que mayor correlación presenta con la variable objetivo, para confirmar o descartar esta hipótesis a través del test de **Mann-Whitney**, puesto que los valores no siguen una distribucion normal y el número de muestras es pequeño.

```{r  message= FALSE, warning=FALSE}
out_perimeter_worst <- boxplot.stats(breast_data_def_corr$Perimeter_worst)$out
out_perimeter_worst_ind <- which(breast_data_def_corr$Perimeter_worst %in% out_perimeter_worst)
out_perimeter_diagnosis <- breast_data_def_corr[out_perimeter_worst_ind,]
in_perimeter_worst <- subset(breast_data_def_corr$Perimeter_worst, !(breast_data_def_corr$Perimeter_worst %in% out_perimeter_diagnosis$Perimeter_worst))
in_perimeter_worst_ind <- which(breast_data_def_corr$Perimeter_worst %in% in_perimeter_worst)
in_perimeter_diagnosis <- breast_data_def_corr[in_perimeter_worst_ind,]

wilcox.test(as.numeric(out_perimeter_diagnosis$Diagnosis),as.numeric(in_perimeter_diagnosis$Diagnosis), alternative = "greater")
```
Tomaremos 0.05 como valor de significacion.
En este caso el p-valor es menor que el  valor de significacion, por lo que aceptamos la hipotesis de que los valores extremos indican  tumores malignos.



------------------------------------------------------------------------------------------------------------------------



A continuación se van a utilizar diferentes métodos de clasificación sobre los atributos indicados anteriormente del conjunto de datos. Posteriormente, se evaluará la calidad de los método usados mediante Validación Cruzada o K-fold Cross Validation. 

Inicialmente se van a crear los grupos de entrenamiento y test, el primero con 2/3 de los datos y el segundo con 1/3 de los datos originales:

```{r message= FALSE, warning=FALSE}
if (!require('caTools')) install.packages('caTools'); library('caTools')

data_to_analyze <- breast_data_def_corr[c('Diagnosis', 'Perimeter_worst', 'Area_mean', 'Concavity_mean', 'Area_se', 'Concavity_worst')]
set.seed(1234)
split <- sample.split(data_to_analyze$Diagnosis, SplitRatio = 0.75)
training_set <- subset(data_to_analyze, split == TRUE)
test_set <- subset(data_to_analyze, split == FALSE)
dim(training_set)
dim(test_set)

```


La distribución de muestras malignas y benignas debe ser simétrica en ambos conjuntos:

```{r}
cat("Porcentaje de muestras benignas y malignas en el conjunto de entrenamiento: ")
prop.table(table(training_set$Diagnosis))
cat("\nPorcentaje de muestras benignas y malignas en el conjunto de test: ")
prop.table(table(test_set$Diagnosis))
```

### Modelo de Regresión Logística

La **Regresión Logística** calcula las probabilidades de ocurrencia de alguna de las clases del modelo a partir del uso de la función logística. Inicialmente se entrena el modelo y se observan los datos estadísticos:


```{r message= FALSE, warning=FALSE}
if (!require('stats')) install.packages('stats'); library('stats')

clasificadorRL <- glm(Diagnosis ~ ., family = binomial, data = training_set)

```

Una vez que el clasificador está entrenado, se puede usar para predecir el resultado. Ya que la regresión logística ofrece como resultado las probabilidades de ocurrencia de cada clase, se va a tomar como umbral el valor de 0.5, de modo que cualquier valor por encima de esa probabilidad se tome como 1 "tumor benigno", y cualquier valor por debajo como 0 como "tumor maligno":


```{r message= FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')

pred_train_RL <- predict(clasificadorRL, type = 'response', ndata = training_set)
pred_train_RL <- ifelse(pred_train_RL > 0.5, 1, 0)
pred_train_RL <- factor(pred_train_RL, levels = c("0", "1"), labels = c("B", "M"))

```

Analizando la matriz de confusión para evaluar la calidad de la predicción:


```{r message= FALSE, warning=FALSE}
matrizConfusion_train_RL <- confusionMatrix(data=pred_train_RL, reference=training_set$Diagnosis, positive = "B",
           dnn = c('Predicción', 'Realidad'))

matrizConfusion_train_RL

```

Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente 405 (259 verdaderos positivos y 146 verdaderos negativos). Asimismo hay 9 falsos negativos (es decir, 9 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 13 falsos positivos (es decir, 13 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tienen una precisión de 0.94% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 0.96% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:


```{r message= FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')

pred_test_RL <- predict(clasificadorRL, type = 'response', newdata = test_set)
pred_test_RL <- ifelse(pred_test_RL > 0.5, 1, 0)
pred_test_RL <- factor(pred_test_RL, levels = c("0", "1"), labels = c("B", "M"))

matrizConfusion_test_RL <- confusionMatrix(data=pred_test_RL, reference=test_set$Diagnosis, positive = "B",
           dnn = c('Predicción', 'Realidad'))

matrizConfusion_test_RL

```

Se observa que de 142 mujeres del grupo de test, con el modelo usado se han clasificado correctamente 135 (86 verdaderos positivos y 49 verdaderos negativos). Asimismo hay 3 falsos negativos (es decir, 3 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 4 falsos positivos (es decir, 4 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tienen una precisión de 0.95% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 0.96% (verdaderos positivos identificados).


### Modelo Naive Bayes
La clasificacion **naive bayes** se basa en el teorema de bayes para clasificar.
```
if (!require('e1071')) install.packages('e1071'); library('e1071')
clasificadorBayes <- naiveBayes(Diagnosis ~ ., data = training_set)
```

Analizando el modelo sobre el conjunto de entrenamiento:

```
pred_valid_bayes <- predict(clasificadorBayes, newdata = training_set)

matrizConfusion_bayes <- confusionMatrix(data=pred_valid_bayes, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_bayes
```
Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 395. El clasificador tienen una precisión de 0.89% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 96% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:

```
pred_valid_bayes <- predict(clasificadorBayes, newdata = test_set)
matrizConfusion_bayes <- confusionMatrix(data=pred_valid_bayes, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_bayes
```

Se observa que de 142 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 129. Ha habido 10 falsos positivos y 3 falsos negativos. El clasificador tienen una precisión de 0.84% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 96% (verdaderos positivos identificados).

### Modelo de Árbol de Decisión


La clasificacion **Decision Tree** se basa en reglas logicas a partir de los datos de entrada.
```
if (!require('rpart')) install.packages('rpart'); library('rpart')
clasificadorDT  <- rpart(Diagnosis ~ ., data = training_set)
```

Analizando el modelo sobre el conjunto de entrenamiento:

```
pred_valid_tree <- predict(clasificadorDT, newdata = training_set)

pred_df <- data.frame(pred_valid_tree)
fact = cut(pred_df$B,2,labels=c("M","B"))
matrizConfusion_tree <- confusionMatrix(data=fact, reference=training_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_tree
```
Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 403 El clasificador tienen una precisión de 0.91% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 96% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:

```
pred_valid_tree <- predict(clasificadorDT, newdata = test_set)
pred_df <- data.frame(pred_valid_tree)
fact = cut(pred_df$B,2,labels=c("M","B"))
matrizConfusion_tree <- confusionMatrix(data=fact, reference=test_set$Diagnosis, positive = "B", dnn = c('Predicción', 'Realidad'))
matrizConfusion_tree
```

Se observa que de 142 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente a 131 Ha habido 5 falsos positivos y 6 falsos negativos. El clasificador tienen una precisión de 0.86% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 93% (verdaderos positivos identificados).



### Modelo Random Forests

La clasificación **Random Forests** construye al azar una gran cantidad de árboles de decisión (__ntree__ en la función usada) sobre un mismo conjunto de datos, y la decisión final de la clasificación es tomada a partir de calcular el voto de la mayoría de las predicciones ofrecidas por cada uno de los árboles que conforman el bosque.

```{r message= FALSE, warning=FALSE}
if (!require('randomForest')) install.packages('randomForest'); library('randomForest')

clasificadorRF <- randomForest(Diagnosis ~ ., data = training_set, ntree = 250)

```


Analizando el modelo sobre el conjunto de entrenamiento:


```{r message= FALSE, warning=FALSE}
pred_train_RF <- predict(clasificadorRF, newdata = training_set)
matrizConfusion_train_RF <- confusionMatrix(data=pred_train_RF, reference=training_set$Diagnosis, positive = "B",
           dnn = c('Predicción', 'Realidad'))
matrizConfusion_train_RF

```
Se observa que de 427 mujeres del grupo de entrenamiento, con el modelo usado se han clasificado correctamente todas ellas. El clasificador tienen una precisión de 0.99% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 1% (verdaderos positivos identificados).

Si hacemos la misma prueba sobre el grupo de test:


```{r message= FALSE, warning=FALSE}
pred_test_RF <- predict(clasificadorRF, newdata = test_set)
matrizConfusion_test_RF <- confusionMatrix(data=pred_test_RF, reference=test_set$Diagnosis, positive = "B",
           dnn = c('Predicción', 'Realidad'))
matrizConfusion_test_RF

```
Se observa que de 142 mujeres del grupo de test, con el modelo usado se han clasificado correctamente 133 (84 verdaderos positivos y 49 verdaderos negativos). Asimismo hay 5 falsos negativos (es decir, 5 mujeres que no tenían cáncer de mama que se predijeron que lo tenían) y 4 falsos positivos (es decir, 4 mujeres que tenían cáncer de mama y que se predijeron que no lo tenían). El clasificador tienen una precisión de 0.93% (mayor al 62% que es el número de mujeres sin cáncer de mama). Por otro lado, el clasificador tiene una sensibilidad del 0.94% (verdaderos positivos identificados).


### Comparación de los modelos usando K-Fold Cross Validation


******
# Representación de los resultados
******

A continuación se van a presentar distintos gráficos estadísticos que demuestran que los datos seleccionados y usados en los clasificadores tienen calidad suficiente para detectar, a partir de una muestra, si un tumor en la mama es benigno o maligno:

```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data_def_corr, aes(x = Perimeter_worst)) + geom_histogram(binwidth = 10, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Perímetro peor para diagnósticos Benignos vs Malignos") +labs(x="Perímetro peor", y="Número de mujeres") 
```

Se observa que las mujeres con diagnóstico benigno tienen un valor de **Perimeter_worst** alrededor del valor 87, mientras que las que tienen un diagnóstico maligno, el valor está por encima de 110.

```{r  message= FALSE, warning=FALSE}
datos_PW_menos100_B <- filter(breast_data_def_corr, breast_data_def_corr$Perimeter_worst <= 100 & breast_data_def_corr$Diagnosis == "B")
total_B <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "B")
valorB <- (nrow(datos_PW_menos100_B)/nrow(total_B))*100
cat("El porcentaje de mujeres con valor inferior a 100 en el atributo peor perímetro (Perimeter_worst) y diagnóstico benigno es: " , valorB , "%\n")

datos_PW_menos100_M <- filter(breast_data_def_corr, breast_data_def_corr$Perimeter_worst <= 100 & breast_data_def_corr$Diagnosis == "M")
total_M <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "M")
valorM <- (nrow(datos_PW_menos100_M)/nrow(total_M))*100
cat("El porcentaje de mujeres con valor inferior a 100 en el atributo peor perímetro (Perimeter_worst) y diagnóstico maligno es: " , valorM , "%")
```


Si analizamos gráficamente el valor de la media del área:


```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data_def_corr, aes(x = Area_mean)) + geom_histogram(binwidth = 45, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Media de área para diagnósticos Benignos vs Malignos") +labs(x="Media de área", y="Número de mujeres") 
```

Se observa que las mujeres con diagnóstico benigno tienen un valor de **Area_mean** mayoritariamente inferior a 600, mientras que las que tienen un diagnóstico maligno, mayoritariamente tiene un valor del atributo por encima de 600.

```{r  message= FALSE, warning=FALSE}
datos_AM_menos600_B <- filter(breast_data_def_corr, breast_data_def_corr$Area_mean <= 600 & breast_data_def_corr$Diagnosis == "B")
total_B <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "B")
valorAMB <- (nrow(datos_AM_menos600_B)/nrow(total_B))*100
cat("El porcentaje de mujeres con valor inferior a 600 en el atributo media de área (Area_mean) y diagnóstico benigno es: " , valorAMB , "%\n")

datos_AM_menos600_M <- filter(breast_data_def_corr, breast_data_def_corr$Area_mean <= 600 & breast_data_def_corr$Diagnosis == "M")
total_M <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "M")
valorAMM <- (nrow(datos_AM_menos600_M)/nrow(total_M))*100
cat("El porcentaje de mujeres con valor inferior a 600 en el atributo media de área (Area_mean) y diagnóstico maligno es: " , valorAMM , "%")
```




 
 Si analizamos gráficamente el valor de la concavidad media:


```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data_def_corr, aes(x =Concavity_mean)) + geom_histogram(binwidth = 0.05, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Concavidad media para diagnósticos Benignos vs Malignos") +labs(x="Concavidad media", y="Número de mujeres") 
```
 
 
Se observa que las mujeres con diagnóstico benigno tienen un valor de **Concavity_mean** mayoritariamente inferior a 0.1, mientras que las que tienen un diagnóstico maligno, mayoritariamente tiene un valor del atributo por encima de 0.1

```{r  message= FALSE, warning=FALSE}
datos_AM_menos600_B <- filter(breast_data_def_corr, breast_data_def_corr$Concavity_mean <= 0.1 & breast_data_def_corr$Diagnosis == "B")
total_B <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "B")
valorAMB <- (nrow(datos_AM_menos600_B)/nrow(total_B))*100
cat("El porcentaje de mujeres con valor inferior a 0.1 en el atributo concavidad media (Concavity_mean) y diagnóstico benigno es: " , valorAMB , "%\n")

datos_AM_menos600_M <- filter(breast_data_def_corr, breast_data_def_corr$Concavity_mean <= 0.1 & breast_data_def_corr$Diagnosis == "M")
total_M <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "M")
valorAMM <- (nrow(datos_AM_menos600_M)/nrow(total_M))*100
cat("El porcentaje de mujeres con valor inferior a 0.1 en el atributo concavidad media (Concavity_mean) y diagnóstico maligno es: " , valorAMM , "%")
```
 
 
 
 'Area_se'
 

  
 Si analizamos gráficamente el valor de la media del área:


```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data_def_corr, aes(x = Area_se)) + geom_histogram(binwidth = 20, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Media de área para diagnósticos Benignos vs Malignos") +labs(x="Media de área", y="Número de mujeres") 
```
 
 
Se observa que las mujeres con diagnóstico benigno tienen un valor de **Area_se** mayoritariamente inferior a 40, mientras que las que tienen un diagnóstico maligno, mayoritariamente tiene un valor del atributo por encima de 40

```{r  message= FALSE, warning=FALSE}
datos_AM_menos600_B <- filter(breast_data_def_corr, breast_data_def_corr$Area_se <= 40 & breast_data_def_corr$Diagnosis == "B")
total_B <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "B")
valorAMB <- (nrow(datos_AM_menos600_B)/nrow(total_B))*100
cat("El porcentaje de mujeres con valor inferior a 40 en el atributo media de área (Area_se) y diagnóstico benigno es: " , valorAMB , "%\n")

datos_AM_menos600_M <- filter(breast_data_def_corr, breast_data_def_corr$Area_se <= 40 & breast_data_def_corr$Diagnosis == "M")
total_M <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "M")
valorAMM <- (nrow(datos_AM_menos600_M)/nrow(total_M))*100
cat("El porcentaje de mujeres con valor inferior a 40 en el atributo media de área (Area_mean) y diagnóstico maligno es: " , valorAMM , "%")
```
 
 
 
 
 'Concavity_worst'
 
  Si analizamos gráficamente el valor de la peor concavidad:


```{r message= FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')

ggplot(breast_data_def_corr, aes(x = Concavity_worst)) + geom_histogram(binwidth = 0.05, col='black', fill='blue') + facet_wrap(~ Diagnosis)+ggtitle("Peor concavidad para diagnósticos Benignos vs Malignos") +labs(x="Peor concavidad", y="Número de mujeres") 
```
 
 
Se observa que las mujeres con diagnóstico benigno tienen un valor de **Concavity_worst** mayoritariamente inferior a 0.25, mientras que las que tienen un diagnóstico maligno, mayoritariamente tiene un valor del atributo por encima de 0.25.

```{r  message= FALSE, warning=FALSE}
datos_AM_menos600_B <- filter(breast_data_def_corr, breast_data_def_corr$Concavity_worst <= 0.25 & breast_data_def_corr$Diagnosis == "B")
total_B <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "B")
valorAMB <- (nrow(datos_AM_menos600_B)/nrow(total_B))*100
cat("El porcentaje de mujeres con valor inferior a 0.25 en el atributo peor concavidad (Concavity_worst) y diagnóstico benigno es: " , valorAMB , "%\n")

datos_AM_menos600_M <- filter(breast_data_def_corr, breast_data_def_corr$Concavity_worst <= 0.25 & breast_data_def_corr$Diagnosis == "M")
total_M <- filter(breast_data_def_corr, breast_data_def_corr$Diagnosis == "M")
valorAMM <- (nrow(datos_AM_menos600_M)/nrow(total_M))*100
cat("El porcentaje de mujeres con valor inferior a 0.25 en el atributo peor concavidad (Concavity_worst) y diagnóstico maligno es: " , valorAMM , "%")
```


******
# Conclusiones
******








